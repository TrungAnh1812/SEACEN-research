{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a48eed4-8e4a-4da0-bb99-c292f2c2b283",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (1676598164.py, line 170)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 170\u001b[1;36m\u001b[0m\n\u001b[1;33m    def local_projection_irf(df, dep_col, shock_col=\"MP_shock_monthly\", age_col=\"Age65_z_m\",\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "# -----------------------------------------\n",
    "# HELPERS\n",
    "# -----------------------------------------\n",
    "def print_section(title):\n",
    "    print(\"\\n\" + \"=\"*len(title))\n",
    "    print(title)\n",
    "    print(\"=\"*len(title))\n",
    "\n",
    "def show_df(name, df, n=5):\n",
    "    print(f\"\\n[{name}] shape={df.shape}\")\n",
    "    print(df.head(n))\n",
    "\n",
    "def nz(x):\n",
    "    return 1.0 if x == 0 else x\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 0 — Load data\n",
    "# -----------------------------------------\n",
    "base = Path(\".\")  # change if needed\n",
    "\n",
    "print_section(\"STEP 0 — Load data\")\n",
    "m_master = pd.read_csv(base / \"vn_monthly_master_new.csv\", parse_dates=[\"Date\"])\n",
    "m_shocks = pd.read_csv(base / \"vn_monthly_with_shocks_new.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "# Robust read for Google Trends (encoding can vary)\n",
    "try:\n",
    "    gtr = pd.read_csv(base / \"google_trends_combined_2013_2024.csv\")\n",
    "except UnicodeDecodeError:\n",
    "    gtr = pd.read_csv(base / \"google_trends_combined_2013_2024.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "show_df(\"Monthly master (no shocks)\", m_master)\n",
    "show_df(\"Monthly with shocks\", m_shocks)\n",
    "show_df(\"Google Trends (raw)\", gtr)\n",
    "\n",
    "# Normalize name and parse\n",
    "if not gtr.columns[0].lower().startswith(\"date\") and gtr.columns[0].lower().startswith(\"month\"):\n",
    "    gtr = gtr.rename(columns={gtr.columns[0]: \"Date\"})\n",
    "elif gtr.columns[0].lower() != \"date\":\n",
    "    gtr = gtr.rename(columns={gtr.columns[0]: \"Date\"})\n",
    "gtr[\"Date\"] = pd.to_datetime(gtr[\"Date\"], errors=\"coerce\")\n",
    "gtr = gtr.dropna(subset=[\"Date\"]).copy()\n",
    "\n",
    "print(\"\\n[Google Trends] columns:\", list(gtr.columns))\n",
    "print(\"[Google Trends] date range:\", gtr[\"Date\"].min().date(), \"→\", gtr[\"Date\"].max().date())\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 1 — Clean & standardize Google Trends, build AI indices\n",
    "# -----------------------------------------\n",
    "print_section(\"STEP 1 — Clean & standardize Google Trends; build AI indices\")\n",
    "\n",
    "gt_numeric_cols = [c for c in gtr.columns if c != \"Date\"]\n",
    "for c in gt_numeric_cols:\n",
    "    gtr[c] = pd.to_numeric(gtr[c], errors=\"coerce\")\n",
    "\n",
    "# Restrict to 2013–2024\n",
    "gtr = gtr[(gtr[\"Date\"].dt.year >= 2013) & (gtr[\"Date\"].dt.year <= 2024)].copy()\n",
    "\n",
    "# Fill small gaps\n",
    "gtr[gt_numeric_cols] = gtr[gt_numeric_cols].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "show_df(\"Google Trends (coerced & trimmed)\", gtr)\n",
    "\n",
    "# Z-score each series\n",
    "gtr_z = gtr.copy()\n",
    "for c in gt_numeric_cols:\n",
    "    s = gtr_z[c].astype(float)\n",
    "    std = s.std(ddof=0)\n",
    "    gtr_z[c] = (s - s.mean()) / nz(std)\n",
    "\n",
    "# Equal-weighted z-average index\n",
    "gtr_z[\"AI_index_zavg\"] = gtr_z[gt_numeric_cols].mean(axis=1)\n",
    "\n",
    "# PCA(1) via SVD\n",
    "X = gtr_z[gt_numeric_cols].to_numpy()\n",
    "if X.ndim == 1 or X.shape[1] == 1:\n",
    "    pc1 = (X[:, 0] - X[:, 0].mean()) / nz(X[:, 0].std(ddof=0))\n",
    "    var_ratio = np.array([1.0])\n",
    "else:\n",
    "    U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    pc1 = U[:, 0] * S[0]\n",
    "    pc1 = (pc1 - pc1.mean()) / nz(pc1.std(ddof=0))\n",
    "    var_ratio = (S**2) / (S**2).sum()\n",
    "\n",
    "gtr_z[\"AI_index_pc1\"] = pc1\n",
    "gtr_idx = gtr_z[[\"Date\", \"AI_index_zavg\", \"AI_index_pc1\"]].copy()\n",
    "show_df(\"AI Indices (for merge)\", gtr_idx)\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 2 — Build analysis panel (merge monthly shocks + AI indices)\n",
    "# -----------------------------------------\n",
    "print_section(\"STEP 2 — Merge AI indices into monthly with shocks + build Age65_z_m\")\n",
    "\n",
    "panel = m_shocks.merge(gtr_idx, on=\"Date\", how=\"left\").sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "if \"Age65_percent\" in panel.columns:\n",
    "    s = panel[\"Age65_percent\"].astype(float)\n",
    "    panel[\"Age65_z_m\"] = (s - s.mean()) / nz(s.std(ddof=0))\n",
    "else:\n",
    "    panel[\"Age65_z_m\"] = np.nan\n",
    "\n",
    "panel = panel[(panel[\"Date\"].dt.year >= 2013) & (panel[\"Date\"].dt.year <= 2024)].copy()\n",
    "\n",
    "show_df(\"Analysis panel (merged)\", panel)\n",
    "\n",
    "analysis_cols = [\n",
    "    \"Date\",\n",
    "    \"IIP_yoy_pct\",\"IIP_mom_pct\",\"IIP_level\",\n",
    "    \"CPI_yoy_pct\",\"CPI_mom_pct\",\"CPI_level\",\n",
    "    \"Credit_yoy_pct\",\"Credit_stock_VNDbn\",\n",
    "    \"ON_avg_monthly_interbank_rate\",\n",
    "    \"MP_shock_monthly\",\n",
    "    \"Age65_percent\",\"Age65_z_m\",\n",
    "    \"AI_index_zavg\",\"AI_index_pc1\"\n",
    "]\n",
    "panel_out = panel[[c for c in analysis_cols if c in panel.columns]].copy()\n",
    "panel_out.to_csv(base / \"vn_monthly_analysis_panel.csv\", index=False)\n",
    "print(\"\\nSaved: vn_monthly_analysis_panel.csv  | shape:\", panel_out.shape)\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 3A — Baseline Local Projections (short horizons only, no interactions)\n",
    "# -----------------------------------------\n",
    "print_section(\"STEP 3A — Baseline Local Projections (short horizons)\")\n",
    "\n",
    "def baseline_lp(df, dep_col, shock_col=\"MP_shock_monthly\",\n",
    "                credit_col=\"Credit_yoy_pct\", horizons=(1,3,6)):\n",
    "    out_rows = []\n",
    "    for h in horizons:\n",
    "        y_lead = df[dep_col].shift(-h) - df[dep_col].shift(1)\n",
    "        X = pd.DataFrame({\n",
    "            \"shock\": df[shock_col].astype(float),\n",
    "            \"credit_growth\": df[credit_col].astype(float) if credit_col in df.columns else np.nan,\n",
    "            \"lag_y\": df[dep_col].shift(1)\n",
    "        })\n",
    "\n",
    "        valid = y_lead.notna() & X.notna().all(axis=1)\n",
    "        Y = y_lead[valid]\n",
    "        Xv = sm.add_constant(X[valid])\n",
    "\n",
    "        mod = sm.OLS(Y, Xv).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": h})\n",
    "        out_rows.append({\n",
    "            \"h\": h,\n",
    "            \"nobs\": int(mod.nobs),\n",
    "            \"R2\": float(mod.rsquared),\n",
    "            \"beta_MP\": mod.params.get(\"shock\", np.nan),\n",
    "            \"se_beta_MP\": mod.bse.get(\"shock\", np.nan)\n",
    "        })\n",
    "        print(f\"dep={dep_col} | h={h} | β={mod.params.get('shock', np.nan):.3f} (SE={mod.bse.get('shock', np.nan):.3f})\")\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "baseline_results = {}\n",
    "for dep in [\"IIP_yoy_pct\", \"CPI_yoy_pct\"]:\n",
    "    if dep in panel_out.columns:\n",
    "        res = baseline_lp(panel_out, dep_col=dep)\n",
    "        baseline_results[dep] = res\n",
    "        res.to_csv(base / f\"baseline_lp_{dep}.csv\", index=False)\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 3B — Extended LP with Age/AI interactions (short horizons only)\n",
    "# -----------------------------------------\n",
    "print_section(\"STEP 3B — Extended LP with ageing & AI interactions\")\n",
    "\n",
    "def local_projection_irf(df, dep_col, shock_col=\"MP_shock_monthly\", age_col=\"Age65_z_m\",\n",
    "                         ai_col=\"AI_index_pc1\", credit_col=\"Credit_yoy_pct\",\n",
    "                         nlags=6, horizons=(1,3,6)):\n",
    "\n",
    "    out_rows = []\n",
    "    for h in horizons:\n",
    "        y_lead = df[dep_col].shift(-h) - df[dep_col].shift(1)\n",
    "        X = pd.DataFrame({\n",
    "            \"shock\": df[shock_col].astype(float),\n",
    "            \"shock_x_age\": df[shock_col]*df[age_col] if age_col in df.columns else np.nan,\n",
    "            \"shock_x_ai\": df[shock_col]*df[ai_col] if ai_col in df.columns else np.nan,\n",
    "            \"credit_growth\": df[credit_col].astype(float) if credit_col in df.columns else np.nan,\n",
    "            \"lag_y\": df[dep_col].shift(1)\n",
    "        })\n",
    "\n",
    "        valid = y_lead.notna() & X.notna().all(axis=1)\n",
    "        Y = y_lead[valid]\n",
    "        Xv = sm.add_constant(X[valid])\n",
    "\n",
    "        mod = sm.OLS(Y, Xv).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": h})\n",
    "        out_rows.append({\n",
    "            \"h\": h, \"nobs\": int(mod.nobs), \"R2\": float(mod.rsquared),\n",
    "            \"beta_MP\": mod.params.get(\"shock\", np.nan), \"se_beta_MP\": mod.bse.get(\"shock\", np.nan),\n",
    "            \"gamma_MPxAge\": mod.params.get(\"shock_x_age\", np.nan), \"se_gamma_MPxAge\": mod.bse.get(\"shock_x_age\", np.nan),\n",
    "            \"delta_MPxAI\": mod.params.get(\"shock_x_ai\", np.nan), \"se_delta_MPxAI\": mod.bse.get(\"shock_x_ai\", np.nan)\n",
    "        })\n",
    "        print(f\"dep={dep_col} | h={h} | β={mod.params.get('shock', np.nan):.3f} \"\n",
    "              f\"(SE={mod.bse.get('shock', np.nan):.3f}) γ={mod.params.get('shock_x_age', np.nan):.3f} \"\n",
    "              f\"δ={mod.params.get('shock_x_ai', np.nan):.3f}\")\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "extended_results = {}\n",
    "for dep in [\"IIP_yoy_pct\", \"CPI_yoy_pct\"]:\n",
    "    if dep in panel_out.columns:\n",
    "        res = local_projection_irf(panel_out, dep_col=dep)\n",
    "        extended_results[dep] = res\n",
    "        res.to_csv(base / f\"extended_lp_{dep}.csv\", index=False)\n",
    "\n",
    "print(\"\\nDONE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640bf39e-08c8-486e-9846-da00eae86d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
